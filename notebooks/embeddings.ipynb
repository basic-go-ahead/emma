{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sentence_transformers import util\n",
    "from emma import Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с векторизатором\n",
    "\n",
    "Векторизацию входного текста, содержащего математические выражения, выполняет `Vectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer(\"basic-go/math-ru-sbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить векторное представление фрагмента текста, необходимо использовать метод `encode` модели векторных представлений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_transcription = \"одна вторая\"\n",
    "\n",
    "half_emb = vectorizer.encode(half_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Числовой вектор, представляющий фрагмент текста, имеет размерность 768:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем примере выражения `uni_expr` и `tex_expr` определяют одно и тоже математическое выражение, причём их векторные представления обладают высокой мерой косинусного сходства. Вместе с тем выражения `tex_expr` и `another_tex_expr` различаются, а отвечающая им мера косинусного сходства имеет меньшее значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9027]])\n",
      "tensor([[0.7251]])\n"
     ]
    }
   ],
   "source": [
    "uni_expr = \"1/α + 1/β = 1/γ\"\n",
    "uni_emb = vectorizer.encode(uni_expr)\n",
    "\n",
    "tex_expr = r\"\\(\\frac{1}{\\alpha} + \\frac{1}{\\beta} = \\frac{1}{\\gamma}\\)\"\n",
    "tex_emb = vectorizer.encode(tex_expr)\n",
    "\n",
    "another_tex_expr = r\"\\(\\alpha + \\beta = \\gamma\\)\"\n",
    "another_tex_emb = vectorizer.encode(another_tex_expr)\n",
    "\n",
    "print(util.cos_sim(uni_emb, tex_emb))\n",
    "print(util.cos_sim(uni_emb, another_tex_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведём пример, демонстрирующий возможность осуществления поиска. Создадим документы для поискового индекса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    tex_expr,\n",
    "    another_tex_expr,\n",
    "    r\"\\(\\frac{1}{3} - x^{2} + \\varphi(x(t))\\)\",\n",
    "    r\"\\( \\frac{1}{2} \\)\",\n",
    "    r\"\\(f : \\mathbb{R}^2 \\to \\mathbb{R}^3\\)\",\n",
    "    r\"\\(\\int \\rho(x) dx\\)\",\n",
    "    r\"\\(\\alpha^2 + \\beta^2 \\neq \\gamma^2\\)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем поисковый индекс, векторизовав все документы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index = vectorizer.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим несколько поисковых запросов, использующих математические символы Unicode, разметку AsciiMath, транскрибацию формул и повреждённую разметку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"∫ ρ(x) dx\",\n",
    "    \"α^2 + β2 ≠ γ^2\",\n",
    "    \"f : RR^(2) -> RR^(3)\",\n",
    "    \"альфа + бета равно гамма\",\n",
    "    \"интеграл ро от икс дэ икс\",\n",
    "     r\"\\( \\frac{1{2 \\)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выполним поиск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрос: ∫ ρ(x) dx\n",
      "Лучший кандидат: \\(\\int \\rho(x) dx\\)\n",
      "Косинусное сходство: 0.9205648899078369\n",
      "\n",
      "Запрос: α^2 + β2 ≠ γ^2\n",
      "Лучший кандидат: \\(\\alpha^2 + \\beta^2 \\neq \\gamma^2\\)\n",
      "Косинусное сходство: 0.9621996283531189\n",
      "\n",
      "Запрос: f : RR^(2) -> RR^(3)\n",
      "Лучший кандидат: \\(f : \\mathbb{R}^2 \\to \\mathbb{R}^3\\)\n",
      "Косинусное сходство: 0.9475846290588379\n",
      "\n",
      "Запрос: альфа + бета равно гамма\n",
      "Лучший кандидат: \\(\\alpha + \\beta = \\gamma\\)\n",
      "Косинусное сходство: 0.9391109943389893\n",
      "\n",
      "Запрос: интеграл ро от икс дэ икс\n",
      "Лучший кандидат: \\(\\int \\rho(x) dx\\)\n",
      "Косинусное сходство: 0.7412841320037842\n",
      "\n",
      "Запрос: \\( \\frac{1{2 \\)\n",
      "Лучший кандидат: \\( \\frac{1}{2} \\)\n",
      "Косинусное сходство: 0.996719479560852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    query_embedding = vectorizer.encode(query)\n",
    "    similarity_scores = util.cos_sim(query_embedding, search_index)[0]\n",
    "    scores, indices = torch.topk(similarity_scores, k=1)\n",
    "\n",
    "    print(\"Запрос:\", query)\n",
    "    print(\"Лучший кандидат:\", documents[indices[0]])\n",
    "    print(\"Косинусное сходство:\", scores[0].item())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
